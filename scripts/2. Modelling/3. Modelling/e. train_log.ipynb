{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the needed package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# package for handling files and directories\n",
    "import os\n",
    "# package for handling file system\n",
    "import sys\n",
    "# add path to utilities directory\n",
    "sys.path.insert(0, './../../')\n",
    "# import the needed path\n",
    "from utilities import path_log_wandb\n",
    "# package for handling the logs history\n",
    "import wandb\n",
    "# package for handling logs tabular data\n",
    "import pandas as pd\n",
    "# package for handling the environment variables\n",
    "from dotenv import load_dotenv\n",
    "# get the environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb variables\n",
    "wandb_repo = \"bugi-sulistiyo-universitas-mulawarman/CAD - Glaucoma Segmentation/\"\n",
    "run_id = os.environ.get(\"RUN_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the training logs from Wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dictionary and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the latest wandb runs id\n",
    "## prepare the dictionary variable to store the runs id\n",
    "runs_id = {}\n",
    "\n",
    "## extract the runs id from the environment variable\n",
    "for element in run_id.split(\",\"):\n",
    "    key, value = element.split(\":\")\n",
    "    runs_id[key] = value\n",
    "\n",
    "# delete the run_id variable\n",
    "del run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dictionary to store the logs file data locally\n",
    "os.makedirs(path_log_wandb, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the wandb api\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the empty dataframe to store the merged logs data\n",
    "merge_df = pd.DataFrame()\n",
    "\n",
    "# download the logs data from wandb\n",
    "for model, log_id in runs_id.items():\n",
    "    # get the run object foro the specific log id in wandb\n",
    "    run = api.run(f\"{wandb_repo}{log_id}\")\n",
    "    # get the log data in tabular format\n",
    "    log_df = run.history()\n",
    "\n",
    "    # sort the values by epoch\n",
    "    log_df.sort_values(by=\"_step\", inplace=True)\n",
    "    # remove the timestamp column\n",
    "    log_df.drop(columns=[\"_timestamp\"], inplace=True)\n",
    "    # rename the epoch column\n",
    "    log_df.rename(columns={\"_step\": \"epoch\"}, inplace=True)\n",
    "    # reorganize the columns order\n",
    "    log_df = log_df[[\"epoch\",\n",
    "                    \"train_loss\", \"train_auc\", \"train_f1\", \"train_accuracy\", \"train_precision\", \"train_recall\",\n",
    "                    \"val_loss\", \"val_auc\", \"val_f1\", \"val_accuracy\", \"val_precision\", \"val_recall\"]]\n",
    "    \n",
    "    # save the log data to the local directory\n",
    "    log_df.to_csv(os.path.join(path_log_wandb, f\"{model}.csv\"), index=False)\n",
    "    # add the model name to the dataframe\n",
    "    log_df[\"model\"] = model\n",
    "    # merge the log data to the merged dataframe\n",
    "    merge_df = pd.concat([merge_df, log_df])\n",
    "\n",
    "# reset the index of the merged dataframe\n",
    "merge_df.reset_index(drop=True, inplace=True)\n",
    "# save the merged dataframe to the local directory\n",
    "merge_df.to_csv(os.path.join(path_log_wandb, \"merged_log.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
